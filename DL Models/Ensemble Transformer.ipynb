{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from transformers import DebertaForSequenceClassification, DebertaTokenizer, RobertaForSequenceClassification, RobertaTokenizer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class FakeNewsDataset(Dataset):\n",
    "    def __init__(self, mode, tokenizer, path, max_seq_length=512):\n",
    "        assert mode in ['train', 'val']\n",
    "        self.mode = mode\n",
    "        self.df = pd.read_csv(path, sep='\\t').fillna('')\n",
    "        self.len = len(self.df)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        statement, label = self.df.iloc[idx, :].values\n",
    "        label_tensor = torch.tensor(label)\n",
    "\n",
    "        tokens = self.tokenizer.tokenize(statement)[:self.max_seq_length - 2]\n",
    "        tokens = [self.tokenizer.cls_token] + tokens + [self.tokenizer.sep_token]\n",
    "\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        tokens_tensor = torch.tensor(ids)\n",
    "\n",
    "        segments_tensor = None\n",
    "        if isinstance(self.tokenizer, DebertaTokenizer):\n",
    "            segments_tensor = torch.tensor([0] * len(tokens), dtype=torch.long)\n",
    "\n",
    "        label_tensor = torch.zeros(NUM_LABELS)\n",
    "        label_tensor[label] = 1\n",
    "\n",
    "        return (tokens_tensor, segments_tensor, label_tensor)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "def create_mini_batch(samples):\n",
    "    tokens_tensors = [s[0] for s in samples]\n",
    "    segments_tensors = [s[1] for s in samples if s[1] is not None]\n",
    "    label_ids = torch.stack([s[2] for s in samples])\n",
    "\n",
    "    tokens_tensors = pad_sequence(tokens_tensors, batch_first=True)\n",
    "    masks_tensors = torch.zeros(tokens_tensors.shape, dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(tokens_tensors != 0, 1)\n",
    "\n",
    "    if len(segments_tensors) > 0:\n",
    "        segments_tensors = pad_sequence(segments_tensors, batch_first=True)\n",
    "        return tokens_tensors, segments_tensors, masks_tensors, label_ids\n",
    "    else:\n",
    "        return tokens_tensors, None, masks_tensors, label_ids\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "MODEL_NAME_DEBERTA = 'microsoft/deberta-base'\n",
    "MODEL_NAME_ROBERTA = 'roberta-base'\n",
    "NUM_LABELS = 3\n",
    "MAX_SEQ_LENGTH = 256\n",
    "train_path = 'train.tsv'\n",
    "val_path = 'val.tsv'\n",
    "model_path_deberta = 'deberta_model.pt'\n",
    "model_path_roberta = 'roberta_model.pt'\n",
    "\n",
    "tokenizer_deberta = DebertaTokenizer.from_pretrained(MODEL_NAME_DEBERTA)\n",
    "tokenizer_roberta = RobertaTokenizer.from_pretrained(MODEL_NAME_ROBERTA)\n",
    "model_deberta = DebertaForSequenceClassification.from_pretrained(MODEL_NAME_DEBERTA, num_labels=NUM_LABELS)\n",
    "model_roberta = RobertaForSequenceClassification.from_pretrained(MODEL_NAME_ROBERTA, num_labels=NUM_LABELS)\n",
    "\n",
    "model_deberta.load_state_dict(torch.load(model_path_deberta))\n",
    "model_roberta.load_state_dict(torch.load(model_path_roberta))\n",
    "\n",
    "valset = FakeNewsDataset('val', tokenizer=tokenizer_deberta, path=val_path, max_seq_length=MAX_SEQ_LENGTH)\n",
    "valloader = DataLoader(valset, batch_size=BATCH_SIZE, collate_fn=create_mini_batch)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model_deberta.to(device)\n",
    "model_roberta.to(device)\n",
    "\n",
    "def apply_post_processing(tokens_tensors, pred, probabilities):\n",
    "    for i, tokens in enumerate(tokens_tensors):\n",
    "        text = tokenizer_deberta.decode(tokens)\n",
    "        max_prob = torch.max(probabilities[i])\n",
    "        \n",
    "        if max_prob < 0.8:  # Increased threshold for applying rules\n",
    "            if 'real' in text.lower() or 'true' in text.lower() or 'factual' in text.lower():\n",
    "                pred[i] = 1\n",
    "            elif 'ai generated' in text.lower() or 'artificial intelligence' in text.lower() or 'machine learning' in text.lower():\n",
    "                pred[i] = 2\n",
    "            elif 'fake' in text.lower() or 'false' in text.lower() or 'misinformation' in text.lower():\n",
    "                pred[i] = 0\n",
    "    return pred\n",
    "\n",
    "def evaluate_ensemble(valloader):\n",
    "    true = []\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        model_deberta.eval()\n",
    "        model_roberta.eval()\n",
    "        for data in valloader:\n",
    "            tokens_tensors, segments_tensors, masks_tensors, labels = [t.to(device) for t in data]\n",
    "            \n",
    "            outputs_deberta = model_deberta(input_ids=tokens_tensors, token_type_ids=segments_tensors, attention_mask=masks_tensors)\n",
    "            outputs_roberta = model_roberta(input_ids=tokens_tensors, attention_mask=masks_tensors)\n",
    "\n",
    "            logits_deberta = outputs_deberta.logits\n",
    "            logits_roberta = outputs_roberta.logits\n",
    "\n",
    "            # Adjust weights\n",
    "            weight_deberta = 0.6\n",
    "            weight_roberta = 0.4\n",
    "            logits = (weight_deberta * logits_deberta + weight_roberta * logits_roberta)\n",
    "\n",
    "            softmax = torch.nn.Softmax(dim=1)\n",
    "            probabilities_deberta = softmax(logits_deberta)\n",
    "            probabilities_roberta = softmax(logits_roberta)\n",
    "            probabilities = softmax(logits)\n",
    "            \n",
    "            # Use model-specific thresholds\n",
    "            threshold_deberta = 0.8\n",
    "            threshold_roberta = 0.8\n",
    "            pred_deberta = torch.argmax(logits_deberta, dim=1)\n",
    "            pred_roberta = torch.argmax(logits_roberta, dim=1)\n",
    "            \n",
    "            # Implement voting system\n",
    "            pred = torch.where(pred_deberta == pred_roberta, pred_deberta,\n",
    "                               torch.where(probabilities.max(dim=1)[0] > 0.9, torch.argmax(logits, dim=1),\n",
    "                                           torch.tensor(-1).to(device)))\n",
    "\n",
    "            # Use probabilities for uncertain predictions\n",
    "            uncertain_mask = pred == -1\n",
    "            pred[uncertain_mask] = torch.argmax(probabilities[uncertain_mask], dim=1)\n",
    "\n",
    "            pred = apply_post_processing(tokens_tensors, pred, probabilities)\n",
    "\n",
    "            labels = data[3]\n",
    "            true.extend(torch.argmax(labels, dim=1).cpu().tolist())\n",
    "            predictions.extend(pred.cpu().tolist())\n",
    "\n",
    "    cm = confusion_matrix(true, predictions, labels=[0, 1, 2], normalize='true')\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Fake', 'Real', 'AI-generated'])\n",
    "    disp.plot(cmap='Blues')\n",
    "\n",
    "    disp.ax_.set_title('Normalized Confusion Matrix')\n",
    "    disp.ax_.tick_params(axis='both', which='major', labelsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    accuracy = accuracy_score(true, predictions)\n",
    "    precision = precision_score(true, predictions, average='weighted')\n",
    "    recall = recall_score(true, predictions, average='weighted')\n",
    "    f1 = f1_score(true, predictions, average='weighted')\n",
    "\n",
    "    print('\\nAccuracy:', accuracy)\n",
    "    print('Precision:', precision)\n",
    "    print('Recall:', recall)\n",
    "    print('F1 Score:', f1)\n",
    "\n",
    "print('Ensemble Model Evaluation:')\n",
    "evaluate_ensemble(valloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
